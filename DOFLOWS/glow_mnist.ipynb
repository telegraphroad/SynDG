{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5Z8fvZS7b67"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VincentStimper/normalizing-flows/blob/master/examples/glow_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3z9qxGv7b68"
      },
      "source": [
        "# Image generation with Glow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhTlHR9L7b68"
      },
      "source": [
        "Here, we show how a flow can be trained to generate images with the `normflows` package. The flow is a class-conditional [Glow](https://arxiv.org/abs/1807.03039) model, which is based on the [multi-scale architecture](https://arxiv.org/abs/1605.08803). This Glow model is applied to the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhC-nvPT7b68"
      },
      "source": [
        "## Perparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcRHXKB97b68"
      },
      "source": [
        "To get started, we have to install the `normflows` package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq8RHdg_7b68",
        "outputId": "b2e94256-a23b-44a2-e7aa-660fd6ccb479"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "K1dXzasr7b69"
      },
      "outputs": [],
      "source": [
        "# Import required packages\n",
        "import torch\n",
        "import torchvision as tv\n",
        "import numpy as np\n",
        "import normflows as nf\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "163sCH1s7b69"
      },
      "source": [
        "Now that we imported the necessary packages, we create a flow model. Glow consists of `nf.flows.GlowBlocks`, that are arranged in a `nf.MultiscaleFlow`, following the multi-scale architecture. The base distribution is a `nf.distributions.ClassCondDiagGaussian`, which is a diagonal Gaussian with mean and standard deviation dependent on the class label of the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CgcQk3C7b69",
        "outputId": "61cbe19c-acae-4e87-f6ae-b2b3e98537ba",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Set up model\n",
        "\n",
        "# Define flows\n",
        "L = 2\n",
        "K = 32\n",
        "torch.manual_seed(0)\n",
        "\n",
        "input_shape = (1, 28, 28)\n",
        "n_dims = np.prod(input_shape)\n",
        "channels = 1\n",
        "hidden_channels = 512\n",
        "split_mode = 'channel'\n",
        "scale = True\n",
        "num_classes = 10\n",
        "\n",
        "# Set up flows, distributions and merge operations\n",
        "q0 = []\n",
        "merges = []\n",
        "flows = []\n",
        "for i in range(L):\n",
        "    flows_ = []\n",
        "    for j in range(K):\n",
        "        flows_ += [nf.flows.GlowBlock(channels * 2 ** (L + 1 - i), hidden_channels,\n",
        "                                     split_mode=split_mode, scale=scale)]\n",
        "    flows_ += [nf.flows.Squeeze()]\n",
        "    flows += [flows_]\n",
        "    if i > 0:\n",
        "        merges += [nf.flows.Merge()]\n",
        "        latent_shape = (input_shape[0] * 2 ** (L - i), input_shape[1] // 2 ** (L - i),\n",
        "                        input_shape[2] // 2 ** (L - i))\n",
        "    else:\n",
        "        latent_shape = (input_shape[0] * 2 ** (L + 1), input_shape[1] // 2 ** L,\n",
        "                        input_shape[2] // 2 ** L)\n",
        "    q0 += [nf.distributions.ClassCondDiagGaussian(latent_shape, num_classes)]\n",
        "\n",
        "\n",
        "# Construct flow model with the multiscale architecture\n",
        "model = nf.MultiscaleFlow(q0, flows, merges)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4ql58qFI7b69"
      },
      "outputs": [],
      "source": [
        "# Move model on GPU if available\n",
        "enable_cuda = True\n",
        "device = torch.device('cuda' if torch.cuda.is_available() and enable_cuda else 'cpu')\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Owz1DyNK7b69"
      },
      "source": [
        "With `torchvision` we can download the CIFAR-10 dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "c0b08kaX7b69"
      },
      "outputs": [],
      "source": [
        "# Prepare training data\n",
        "batch_size = 128\n",
        "\n",
        "normalize = tv.transforms.Normalize((0.1307,), (0.3081,))\n",
        "\n",
        "transform = tv.transforms.Compose([tv.transforms.Grayscale(num_output_channels=3),tv.transforms.ToTensor(), normalize])\n",
        "transform = tv.transforms.Compose([tv.transforms.ToTensor(), normalize])\n",
        "train_data = tv.datasets.MNIST('datasets/', train=True,\n",
        "                                 download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True,\n",
        "                                           drop_last=True)\n",
        "\n",
        "test_data = tv.datasets.MNIST('datasets/', train=False,\n",
        "                                download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "train_iter = iter(train_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsA8rWoS7b69"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wq69gjrx7b69"
      },
      "source": [
        "Now, can train the model on the image data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        },
        "id": "56IYF7Ki7b69",
        "outputId": "dea0ff04-e47f-459b-b8f8-049437ea58ad",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/20000 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "cuDNN error: CUDNN_STATUS_NOT_INITIALIZED",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(train_iter)\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 15\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_kld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m~\u001b[39m(torch\u001b[38;5;241m.\u001b[39misnan(loss) \u001b[38;5;241m|\u001b[39m torch\u001b[38;5;241m.\u001b[39misinf(loss)):\n\u001b[1;32m     18\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
            "File \u001b[0;32m~/anaconda3/envs/syndg/lib/python3.11/site-packages/normflows/core.py:631\u001b[0m, in \u001b[0;36mMultiscaleFlow.forward_kld\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_kld\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    622\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Estimates forward KL divergence, see see [arXiv 1912.02762](https://arxiv.org/abs/1912.02762)\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \n\u001b[1;32m    624\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;124;03m      Estimate of forward KL divergence averaged over batch\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mtorch\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m)\n",
            "File \u001b[0;32m~/anaconda3/envs/syndg/lib/python3.11/site-packages/normflows/core.py:746\u001b[0m, in \u001b[0;36mMultiscaleFlow.log_prob\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq0) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    745\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflows[i]) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 746\u001b[0m         z, log_det \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflows\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m         log_q \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m log_det\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "File \u001b[0;32m~/anaconda3/envs/syndg/lib/python3.11/site-packages/normflows/flows/affine/glow.py:82\u001b[0m, in \u001b[0;36mGlowBlock.inverse\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m     80\u001b[0m log_det_tot \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(z\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mz\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mz\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflows) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 82\u001b[0m     z, log_det \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflows\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m     log_det_tot \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m log_det\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m z, log_det_tot\n",
            "File \u001b[0;32m~/anaconda3/envs/syndg/lib/python3.11/site-packages/normflows/flows/mixing.py:131\u001b[0m, in \u001b[0;36mInvertible1x1Conv.inverse\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m    129\u001b[0m     log_det \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mslogdet(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    130\u001b[0m W \u001b[38;5;241m=\u001b[39m W\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_channels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_channels, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 131\u001b[0m z_ \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m log_det \u001b[38;5;241m=\u001b[39m log_det \u001b[38;5;241m*\u001b[39m z\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m*\u001b[39m z\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m z_, log_det\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED"
          ]
        }
      ],
      "source": [
        "# Train model\n",
        "max_iter = 20000\n",
        "\n",
        "loss_hist = np.array([])\n",
        "\n",
        "optimizer = torch.optim.Adamax(model.parameters(), lr=5e-4, weight_decay=5e-4)\n",
        "pbar = tqdm(range(max_iter))\n",
        "for i in pbar:\n",
        "    try:\n",
        "        x, y = next(train_iter)\n",
        "    except StopIteration:\n",
        "        train_iter = iter(train_loader)\n",
        "        x, y = next(train_iter)\n",
        "    optimizer.zero_grad()\n",
        "    loss = model.forward_kld(x.to(device), y.to(device))\n",
        "\n",
        "    if ~(torch.isnan(loss) | torch.isinf(loss)):\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    loss_hist = np.append(loss_hist, loss.detach().to('cpu').numpy())\n",
        "    pbar.set_description(f\"Loss: {loss:.4f}\")\n",
        "    if i % 100 == 1:\n",
        "        num_sample = 10\n",
        "\n",
        "        # with torch.no_grad():\n",
        "        #     x_ = torch.clamp(x, 0, 1)\n",
        "        #     plt.figure(figsize=(10, 10))\n",
        "        #     plt.imshow(np.transpose(tv.utils.make_grid(x_, nrow=num_classes).cpu().numpy(), (1, 2, 0)))\n",
        "        #     plt.show()\n",
        "        # num_sample = 10\n",
        "\n",
        "        with torch.no_grad():\n",
        "            y = torch.arange(num_classes).repeat(num_sample).to(device)\n",
        "            x, _ = model.sample(y=y)\n",
        "            x_ = torch.clamp(x, 0, 1)\n",
        "            plt.figure(figsize=(10, 10))\n",
        "            plt.imshow(np.transpose(tv.utils.make_grid(x_, nrow=num_classes).cpu().numpy(), (1, 2, 0)))\n",
        "            plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WiOzP05m7b69"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "plt.plot(loss_hist, label='loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wm_76-Rc7b69"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSDlz1fe7b69"
      },
      "source": [
        "To evaluate our model, we first draw samples from our model. When sampling, we can specify the classes, so we draw then samples from each class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "valN2wAG7b6-",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Model samples\n",
        "num_sample = 10\n",
        "\n",
        "with torch.no_grad():\n",
        "    y = torch.arange(num_classes).repeat(num_sample).to(device)\n",
        "    x, _ = model.sample(y=y)\n",
        "    x_ = torch.clamp(x, 0, 1)\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(np.transpose(tv.utils.make_grid(x_, nrow=num_classes).cpu().numpy(), (1, 2, 0)))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-Xw1v5o7b6-"
      },
      "source": [
        "For quantitative evaluation, we can compute the bits per dim of our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3HcoTVH7b6-"
      },
      "outputs": [],
      "source": [
        "# Get bits per dim\n",
        "n = 0\n",
        "bpd_cum = 0\n",
        "with torch.no_grad():\n",
        "    for x, y in iter(test_loader):\n",
        "        nll = model(x.to(device), y.to(device))\n",
        "        nll_np = nll.cpu().numpy()\n",
        "        bpd_cum += np.nansum(nll_np / np.log(2) / n_dims + 8)\n",
        "        n += len(x) - np.sum(np.isnan(nll_np))\n",
        "\n",
        "    print('Bits per dim: ', bpd_cum / n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azDnb5Ch7b6-"
      },
      "source": [
        "Note that to get competitive performance, a much larger model then specified in this notebook, which is trained over 100 thousand to 1 million iterations, is needed."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
